{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import warnings\n",
        "import time\n",
        "import json\n",
        "from itertools import chain\n",
        "from typing import Dict, List\n",
        "import asyncio as ai\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from fake_headers import Headers\n",
        "from bs4 import BeautifulSoup\n",
        "from returns.io import IO\n",
        "from lxml import html"
      ],
      "attachments":{
        
      },
      "execution_count":78,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "'''\n",
        "Общий алгоритм работы\n",
        "---------------------\n",
        "-> Определь неизменяемые входные данные ({url, domain, headers{browser,os,headers}}).\n",
        "-> Получить общее количество страниц пагинации с данными (товарами)\n",
        "-> Получить url всех страниц пагинации (в случае e-katalog это порядковый номер страницы)\n",
        "-> Получить список списков со всеми url конкретного товарова со всех страниц.\n",
        "-> Распаковать все списки в один список.\n",
        "-> Добавить ко всем url домен, как итог список окончательных ссылок к товару.\n",
        "_____________________\n",
        "'''"
      ],
      "attachments":{
        
      },
      "execution_count":18,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "'\\nОбщий алгоритм работы\\n---------------------\\n-> Определь неизменяемые входные данные ({url, domain, headers{browser,os,headers}}).\\n-> Получить общее количество страниц пагинации с данными (товарами)\\n-> Получить url всех страниц пагинации (в случае e-katalog это порядковый номер страницы)\\n-> Получить список списков со всеми url конкретного товарова со всех страниц.\\n-> Распаковать все списки в один список.\\n-> Добавить ко всем url домен, как итог список окончательных ссылок к товару.\\n_____________________\\n'"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "warnings.filterwarnings('ignore')"
      ],
      "attachments":{
        
      },
      "execution_count":19,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "class imdict(dict):\n",
        "    def __hash__(self):\n",
        "        return id(self)\n",
        "\n",
        "    def _immutable(self, *args, **kws):\n",
        "        raise TypeError('object is immutable')\n",
        "\n",
        "    __setitem__ = _immutable\n",
        "    __delitem__ = _immutable\n",
        "    clear       = _immutable\n",
        "    update      = _immutable\n",
        "    setdefault  = _immutable\n",
        "    pop         = _immutable\n",
        "    popitem     = _immutable"
      ],
      "attachments":{
        
      },
      "execution_count":20,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "data = imdict({'URL':'https:\/\/www.e-katalog.ru\/list\/61\/',\n",
        "               'DOMAIN': 'https:\/\/www.e-katalog.ru'})\n",
        "\n",
        "headers =imdict({'browser':\"chrome\",\n",
        "                 'os':\"win\",\n",
        "                 'headers': True})"
      ],
      "attachments":{
        
      },
      "execution_count":21,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def generate_headers(headers_setting: Dict) -> IO[Dict]:\n",
        "    '''\n",
        "    Генерирует html заголовки запросов. В данном случае фейковые.\n",
        "    '''\n",
        "    #TODO Расширить количество аргументов.\n",
        "\n",
        "    return Headers(\n",
        "                   browser = headers_setting['browser'],\n",
        "                   os = headers_setting['os'],\n",
        "                   headers = headers_setting['headers']\n",
        "                   ).generate()"
      ],
      "attachments":{
        
      },
      "execution_count":22,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def get_page_html(url: str, verify: bool = False) -> IO[BeautifulSoup]:\n",
        "    '''На основе url получает всю html страницы, без потверждения ssl(опционально)'''\n",
        "\n",
        "    time.sleep(1)\n",
        "    return BeautifulSoup(requests.get(url, verify=verify).content, 'html.parser')"
      ],
      "attachments":{
        
      },
      "execution_count":23,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def get_product_amount_page(url: str, headers: Dict = generate_headers(headers)) -> IO[int]:\n",
        "  \n",
        "    '''\n",
        "    Возвращает общее количество страниц для конкретного типа продукта\n",
        "    | ---\n",
        "    | url = базовый url страницы конкретного продукта (data['url'])\n",
        "    | headers = Шапка html запроса в формате словаря.\n",
        "    | ---\n",
        "    '''\n",
        "\n",
        "    def page_count(tree):\n",
        "        return tree.xpath('\/\/div[@class=\"ib page-num\"]\/\/a[last()]\/text()')   \n",
        "\n",
        "    return int(page_count(html.fromstring(requests.get(url, headers = headers).content))[0])"
      ],
      "attachments":{
        
      },
      "execution_count":24,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def collect_product_pages(url: str, pages_count: int) -> List[str]:\n",
        "    '''\n",
        "    *Получает список url страниц с товарами.*\n",
        "    | ---\n",
        "    | url = базовый url страницы конкретного продукта (data['url'])\n",
        "    | pages_count = Общее количество страниц для продукта.\n",
        "    | ---\n",
        "    '''\n",
        "    return list(map(lambda x: url + f\"{x}\/\", range(1, pages_count+1)))"
      ],
      "attachments":{
        
      },
      "execution_count":25,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def collect_url_from_page(page_url: str, headers = generate_headers(headers), sleep: int = 1) -> IO[List[str]]:\n",
        "    '''\n",
        "    *Получает все url продуктов со страницы(получает список страницы), возвращает список url*\n",
        "    | ---\n",
        "    | page_url = url страницы со товармаи\n",
        "    | headers = Шапка html запроса в формате словаря\n",
        "    | sleep = Время задержки после запроса\n",
        "    | ---\n",
        "    '''\n",
        "\n",
        "    def get_product_url(tree):\n",
        "        return tree.xpath(\"\/\/a[@class='model-short-title no-u no-u']\/@href\")\n",
        "    \n",
        "    time.sleep(sleep)\n",
        "    return get_product_url(html.fromstring(requests.get(page_url, headers=headers).content))\n",
        "    "
      ],
      "attachments":{
        
      },
      "execution_count":26,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "def get_product_data(bs4: BeautifulSoup) -> IO[Dict[str, str]]:\n",
        "    '''Получает BeautifulSoup объект. Получает имя товара, и таблицу с характеристиками'''\n",
        "\n",
        "    _ = dict()\n",
        "    _.update({'Наименование товара' : bs4.find(\"div\", class_= \"op1-tt\").text})\n",
        "\n",
        "\n",
        "    for value in bs4.find_all(\"table\", class_=\"one-col\")[0].contents:\n",
        "\n",
        "        try:\n",
        "            _.update({value.find(\"span\", class_=\"gloss\").text : value.find(\"td\", class_=\"val\").text}) \n",
        "\n",
        "        except AttributeError:\n",
        "            continue \n",
        "\n",
        "    return _"
      ],
      "attachments":{
        
      },
      "execution_count":32,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "pages_urls = collect_product_pages(\n",
        "                                   data['URL'], get_product_amount_page(\n",
        "                                                                        data['URL'],\n",
        "                                                                        generate_headers(headers)\n",
        "                                                                        )\n",
        "                                   )"
      ],
      "attachments":{
        
      },
      "execution_count":28,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "all_url_product = list(\n",
        "                       chain(\n",
        "                             *list(\n",
        "                                   map(\n",
        "                                       collect_url_from_page, pages_urls\n",
        "                                       )\n",
        "                                   )\n",
        "                             )\n",
        "                       ) # Распоковка всех списков"
      ],
      "attachments":{
        
      },
      "execution_count":29,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "full_url_path_to_product = list(\n",
        "                                map(\n",
        "                                    lambda x: data['DOMAIN'] + x, all_url_product\n",
        "                                    )\n",
        "                                )"
      ],
      "attachments":{
        
      },
      "execution_count":33,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "def create_json(urls: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
        "\n",
        "    global get_product_data, get_page_html\n",
        "\n",
        "    def data_list(url):\n",
        "        data = get_product_data(get_page_html(url))\n",
        "        data.update({'url' : url})\n",
        "        return data\n",
        "\n",
        "    return {'SSD': list(map(data_list,urls))}\n",
        "\n",
        "#json.dump(ssd, f, indent=4, ensure_ascii=False)"
      ],
      "attachments":{
        
      },
      "execution_count":79,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "data_ssd = create_json(full_url_path_to_product)"
      ],
      "attachments":{
        
      },
      "execution_count":80,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}